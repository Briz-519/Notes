## 爬虫项目1

## 准备工作

首行填写防止中文乱码：#coding=utf-8

可加入main函数用于测试程序：

```python
if __name__ =="__main__"    #等同于C语言等其他语言的主函数
```

引入模块：

> 本质为.py文件，用于提高代码的可维护性，可使用import来导入模块

import sys 系统函数库

import bs4 网页解析获取数据

import sqlite3 进行SQLite数据库操作

import urllib.request,urllib.error 制定URL获取网页数据

import xlwt 进行EXCEL操作

import re 正则表达式进行文字匹配

> `模块 module`：一般情况下，是一个以.py为后缀的文件。 module 可看作一个工具类，可共用或者隐藏代码细节，将相关代码放置在一个module以便让代码更 好用、易懂，让coder重点放在高层逻辑上。 module能定义函数、类、变量，也能包含可执行的代码。module来源有3种： ①Python内置的模块（标准库）； ②第三方模块； ③自定义模块。 
>
> `包 package`： 为避免模块名冲突，Python引入了按目录组织模块的方法，称之为 包（package）。包 是含有Python模块的文件夹。

### urllib模块

是最基本的python内置的一个http请求库，不需要额外的安装。只需要关注请求的链接，参数，提供了强大的解析功能

`urllb.request 请求模块` 

`urllib.error 异常处理模块` 

`urllib.parse 解析模块`

简单的一个get请求

```python
import urllib.request     #引入库
reponse = urllib.request.urlopen('http://www.baidu.com') 
print(reponse.read().decode('utf-8'))    #decode("utf-8")将数据解码为utf-8格式数据
```

简单的一个post请求

```python
import urllib.parse
import urllib.request
data = bytes(urllib.parse.urlencode({'hello':'world'}),encoding='utf-8')
reponse = urllib.request.urlopen('http://httpbin.org/post',data=data)
print(reponse.read().decode('utf-8'))
```

超时处理

```python
import urllib.request
try:
    response=urllib.request.urlopen("http://httpbin.org/get",timeout=0.01)    #设置超时时间防止无限加载
    print(response.read().decode("utf-8"))
except urllib.error.URLError as e:
    print("Time out!")
```

```python
import urllib.request
response = urllib.request.urlopen('http://www.baidu.com')
print(response.status) # 状态码 判断请求是否成功
print(response.getheaders()) # 响应头 得到的一个元组组成的列表
print(response.getheader('Server')) #得到特定的响应头
print(response.read().decode('utf-8')) #获取响应体的内容，字节流的数据，需要转成utf-8
格式
```

由于通过Pycharm获取网页信息会被网站的反爬虫识别，因此可以通过修改hearers里的user-agent来伪装成浏览器发送请求

```python
from urllib import request,parse
url="http://httpbin.org/post"
data=bytes(urllib.parse.urlencode({"name":"Briz"}),encoding="utf-8")
headers={"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36 Edg/83.0.478.58"}    
req=urllib.request.Request(url=url,headers=headers,data=data,method="POST")
response=urllib.request.urlopen(req)
print(response.read().decode("utf-8"))

```

> 获取user-agent方法：

![image-20200705182757465](爬虫项目1.assets/image-20200705182757465.png)

> ###### urlopen()方法中的url参数可以是字符串，也可以是一个Request对象

```python
#url可以是字符串
import urllib.request
resp = urllib.request.urlopen('http://www.baidu.com')
print(resp.read().decode('utf-8'))  # read()获取响应体的内容，内容是bytes字节流，需要转换成字符串

##url可以也是Request对象
import urllib.request
request = urllib.request.Request('http://httpbin.org')
response = urllib.request.urlopen(request)
print(response.read().decode('utf-8'))
```

### BeautifulSoup模块

Beautiful Soup 是一个HTML/XML的解析器，主要的功能是如何解析和提取 HTML/XML 数据。

> BeautifulSoup支持Python标准库中的HTML解析器,还支持一些第三方的解析器，如果我们不安装它， 则 Python 会使用 Python默认的解析器，lxml 解析器更加强大，速度更快，推荐使用lxml 解析器。 Beautiful Soup自动将输入文档转换为Unicode编码，输出文档转换为utf-8编码。你不需要考虑编码方 式，除非文档没有指定一个编码方式，这时，Beautiful Soup就不能自动识别编码方式了。然后，你仅仅需要说明一下原始编码方式就可以了。

创建BeautifulSoup4对象

```python
from bs4 import BeautifulSoup
file = open('./aa.html', 'rb')
html = file.read()
bs = BeautifulSoup(html,"html.parser") # 缩进格式
```

#### BeautifulSoup4四大对象种类

BeautifulSoup4将复杂HTML文档转换成一个复杂的树形结构,每个节点都是Python对象,所有对象可以 归纳为4种: 

`Tag` 

`NavigableString` 

`BeautifulSoup` 

`Comment`

##### Tag 

Tag通俗点讲就是HTML中的一个个标签，例如：

```python
from bs4 import BeautifulSoup
file = open('./aa.html', 'rb')
html = file.read()
bs = BeautifulSoup(html,"html.parser")

print(bs.title)# 获取title标签的所有内容

print(bs.head)# 获取head标签的所有内容

print(bs.a)# 获取第一个a标签的所有内容

print(type(bs.a))# 类型
```

> 我们可以利用 soup 加标签名轻松地获取这些标签的内容，这些对象的类型是bs4.element.Tag。但是，它查找的是在所有内容中的`第一个`符合要求的标签(不包括被注释的)。

对于 Tag，它有两个重要的属性，是 name 和 attrs：

```python
from bs4 import BeautifulSoup
file = open('./aa.html', 'rb')
html = file.read()
bs = BeautifulSoup(html,"html.parser")

print(bs.name)# [document] #bs 对象本身比较特殊，它的 name 即为 [document]

print(bs.head.name)# head #对于其他内部标签，输出的值便为标签本身的名称

print(bs.a.attrs)# 把 a 标签的所有属性打印输出了出来，得到的类型是一个字典。

print(bs.a['class']) # 等价 bs.a.get('class')

bs.a['class'] = "newClass"# 可以对这些属性和内容等等进行修改

del bs.a['class']# 对这个属性进行删除

```

##### NavigableString

```python
from bs4 import BeautifulSoup
file = open('./aa.html', 'rb')
html = file.read()
bs = BeautifulSoup(html,"html.parser")
print(bs.title.string)    #获取标签内部的文字
print(type(bs.title.string))
```

##### BeautifulSoup

BeautifulSoup对象表示的是一个文档的内容。大部分时候，可以把它当作 Tag 对象，是一个特殊的 Tag，我们可以分别获取它的类型，名称，以及属性

```python
from bs4 import BeautifulSoup
file = open('./aa.html', 'rb')
html = file.read()
bs = BeautifulSoup(html,"html.parser")
print(type(bs.name))
print(bs.name)
print(bs.attrs)
{'class': ['mnav'], 'href': 'http://news.baidu.com', 'name': 'tj_trnews'}
```

##### Comment

Comment 对象是一个特殊类型的 NavigableString 对象，其输出的内容不包括注释符号

```python
from bs4 import BeautifulSoup
file = open('./aa.html', 'rb')
html = file.read()
bs = BeautifulSoup(html,"html.parser")
print(bs.a)
# 此时不能出现空格和换行符，a标签如下：
# <a class="mnav" href="http://news.baidu.com" name="tj_trnews"><!--新闻--></a>
print(bs.a.string) # 新闻
print(type(bs.a.string)) # <class 'bs4.element.Comment'>
```

#### 遍历文档树

5.1 .contents：获取Tag的所有子节点，返回一个list

```python
# tag的.content 属性可以将tag的子节点以列表的方式输出
print(bs.head.contents)
# 用列表索引来获取它的某一个元素
print(bs.head.contents[1])
```

5.2 .children：获取Tag的所有子节点，返回一个生成器

```python
for child in bs.body.children:
print(child)
```

> 5.3、.descendants：获取Tag的所有子孙节点 
>
> 5.4、.strings：如果Tag包含多个字符串，即在子孙节点中有内容，可以用此获取，而后进行遍历
>
> 5.5、.stripped_strings：与strings用法一致，只不过可以去除掉那些多余的空白内容 
>
> 5.6、.parent：获取Tag的父节点 
>
> 5.7、.parents：递归得到父辈元素的所有节点，返回一个生成器 
>
> 5.8、.previous_sibling：获取当前Tag的上一个节点，属性通常是字符串或空白，真实结果是当前标签 与上一个标签之间的顿号和换行符 
>
> 5.9、.next_sibling：获取当前Tag的下一个节点，属性通常是字符串或空白，真是结果是当前标签与下 一个标签之间的顿号与换行符 
>
> 5.10、.previous_siblings：获取当前Tag的上面所有的兄弟节点，返回一个生成器 
>
> 5.11、.next_siblings：获取当前Tag的下面所有的兄弟节点，返回一个生成器 
>
> 5.12、.previous_element：获取解析过程中上一个被解析的对象(字符串或tag)，可能与 previous_sibling相同，但通常是不一样的 
>
> 5.13、.next_element：获取解析过程中下一个被解析的对象(字符串或tag)，可能与next_sibling相同， 但通常是不一样的 
>
> 5.14、.previous_elements：返回一个生成器，可以向前访问文档的解析内容 
>
> 5.15、.next_elements：返回一个生成器，可以向后访问文档的解析内容 
>
> 5.16、.has_attr：判断Tag是否包含属性

#### 搜索文档树

find_all(name, attrs, recursive, text, **kwargs)

##### name参数：

字符串过滤：会查找与字符串完全匹配的内容

```python
a_list = bs.find_all("a")
print(a_list)
```

正则表达式过滤：如果传入的是正则表达式，那么BeautifulSoup4会通过search()来匹配内容

```python
from bs4 import BeautifulSoup
import re
file = open('./aa.html', 'rb')
html = file.read()
bs = BeautifulSoup(html,"html.parser")
t_list = bs.find_all(re.compile("a"))    #列表输出所有带a的标签
for item in t_list:
print(item)
```

##### kwargs参数：

```python
from bs4 import BeautifulSoup
import re
file = open('./aa.html', 'rb')
html = file.read()
bs = BeautifulSoup(html,"html.parser")
# 查询id=head的Tag
t_list = bs.find_all(id="head")
print(t_list)
# 查询href属性包含news.baidu.com的Tag
t_list = bs.find_all(href=re.compile("http://news.baidu.com"))
print(t_list)
# 查询所有包含class的Tag(注意：class在Python中属于关键字，所以加_以示区别)
t_list = bs.find_all(class_=True)
for item in t_list:
print(item)
```

##### text参数：

通过text参数可以搜索文档中的字符串内容，与name参数的可选值一样，text参数接受 字符串，正则 表达式，列表

```python
from bs4 import BeautifulSoup
import re
file = open('./aa.html', 'rb')
html = file.read()
bs = BeautifulSoup(html, "html.parser")
t_list = bs.find_all(attrs={"data-foo": "value"})
for item in t_list:
print(item)
t_list = bs.find_all(text="hao123")
for item in t_list:
print(item)
t_list = bs.find_all(text=["hao123", "地图", "贴吧"])
for item in t_list:
print(item)
t_list = bs.find_all(text=re.compile("\d"))    #带有数字的内容
for item in t_list:
print(item)
```

当我们搜索text中的一些特殊属性时，同样也可以传入一个方法来达到我们的目的：

```python
def length_is_two(text):
return text and len(text) == 2
t_list = bs.find_all(text=length_is_two)
for item in t_list:
print(item)
```

##### limit参数：

可以传入一个limit参数来限制返回的数量，当搜索出的数据量为5，而设置了limit=2时，此时只会返回 前2个数据

```python
from bs4 import BeautifulSoup
import re
file = open('./aa.html', 'rb')
html = file.read()
bs = BeautifulSoup(html, "html.parser")
t_list = bs.find_all("a",limit=2)
for item in t_list:
print(item)
```

find_all除了上面一些常规的写法，还可以对其进行一些简写：

```python
# 两者是相等的
# t_list = bs.find_all("a") => t_list = bs("a")
t_list = bs("a") # 两者是相等的
# t_list = bs.a.find_all(text="新闻") => t_list = bs.a(text="新闻")
t_list = bs.a(text="新闻")
```

find()

find()将返回符合条件的第一个Tag，有时我们只需要或一个Tag时，我们就可以用到find()方法了。当然 了，也可以使用find_all()方法，传入一个limit=1，然后再取出第一个值也是可以的，不过未免繁琐。

```python
from bs4 import BeautifulSoup
import re
file = open('./aa.html', 'rb')
html = file.read()
bs = BeautifulSoup(html, "html.parser")
# 返回只有一个结果的列表
t_list = bs.find_all("title",limit=1)
print(t_list)
# 返回唯一值
t = bs.find("title")
print(t)
# 如果没有找到，则返回None
t = bs.find("abc") print(t)
#从结果可以看出find_all，尽管传入了limit=1，但是返回值仍然为一个列表，当我们只需要取一个值时，远不如find方法方便。但是如果未搜索到值时，将返回一个None
```

#### CSS选择器

BeautifulSoup支持发部分的CSS选择器，在Tag获取BeautifulSoup对象的.select()方法中传入字符串参 数，即可使用CSS选择器的语法找到Tag:

7.1、通过标签名查找 

```python
print(bs.select('title'))
print(bs.select('a'))
```

7.2、通过类名查找 

print(bs.select('.mnav'))    #.对应class

7.3、通过id查找 

print(bs.select('#u1'))    ##对应id

7.4、组合查找 

print(bs.select('div .bri'))    #div标签内id为bri

7.5、属性查找 

print(bs.select('a[class="bri"]')) 

print(bs.select('a[href="http://tieba.baidu.com"]'))

7.6、直接子标签查找 

t_list = bs.select("head > title") 

print(t_list)

7.7、兄弟节点标签查找

t_list = bs.select(".mnav ~ .bri") 

print(t_list)

7.8、获取内容

t_list = bs.select("title") 

print(bs.select('title')[0].get_text())    #获取title标签内的内容

### re模块

#### 正则表达式常用操作符

| 操作符 | 说明                                | 实例                                            |
| ------ | ----------------------------------- | ----------------------------------------------- |
| .      | 表示任何单个字符                    |                                                 |
| [ ]    | 字符集，对单个字符给予取值范围      | [abc]表示a,b,c，[a-z]表示a到z单个字符           |
| [^ ]   | 非字符集，对单个字符给出取值范围    | [^abc]表示非a或b或c的单个字符                   |
| *      | 前一个字符`0`次或无限次扩展         | abc*表示ab,abc,abcc,abccc等                     |
| +      | 前一个字符`1`次或无限次扩展         | abc+表示abc,abcc,abccc等                        |
| ？     | 前一个字符0次或1次扩展              | abc?表示ab,abc                                  |
| \|     | 左右表达式任意一个                  | abc\|def表示abc,def                             |
| {m}    | 扩展前一个字符m次                   | ab{2}c表示abbc                                  |
| {m,n}  | 扩展前一个字符m至n次（含n）         | ab{1,3}c表示abc,abbc,abbbc                      |
| ^      | 匹配字符串开头                      | ^abc表示abc且在一个字符串的开头                 |
| $      | 匹配字符串结尾                      | abc$表示abc且在一个字符串的结尾                 |
| ( )    | 分组标记，内部可使用\|操作符        | (abc)表示abc ,(abc\|def)表示abc，def            |
| \d     | 数字，等价于[0-9]                   |                                                 |
| \w     | 单词字符，等价于[A-Z]/[a-z]/[0-9]/_ | 网站注册用户名(只能使用大小写字母数字和下划线 ) |

> “?” ：0次或1次，match,search 不会出现none，会出现’ ‘ （因为0次也是符合的） 0次或1次不是指[xxx]这个集合，而是其中的任何的一个字符
>
> ```python
> pat = re.compile( [abc]? )
> pat.match( defabc ).group() #0次
> pat.match( abcdefabc ).group()
> >>> a
> pat.search( defabc ).group() #0次
> pat.findall( defabc ) #0次和1次
> >>> [ , , , a , b , c , ]
> ```
>
> “数量词?” ：`非贪婪模式`：只匹配最少的（尽可能少）；默认贪婪模式：匹配最多的（尽可能多）
>
> ```python
> pat = re.compile( [abc]+ ) #贪婪模式
> >>> pat.match( abcdefabcabc ).group() #匹配尽可能多的：abc
> >>> abc
> >>> pat.match( bbabcdefabcabc ).group()
> >>> bbabc
> >>> pat.search( dbbabcdefabcabc ).group()
> >>> bbabc
> >>> pat.findall( abcdefabcabc )
> >>> [ abc , abcabc ]
> >>> pat = re.compile( [abc]+? ) #非贪婪模式：+?
> >>> pat.match( abcdefabcabc ).group() #匹配尽可能少的：a、b、c
> >>> a
> >>> pat.search( dbbabcdefabcabc ).group()
> >>> b
> >>> pat.findall( abcdefabcabc )
> >>> [ a , b , c , a , b , c , a , b , c ]
> ```

#### Re库主要功能函数

| 函数          | 说明                                                         |
| ------------- | ------------------------------------------------------------ |
| re.search()   | 在一个字符串中国搜索匹配正则表达式的第一个位置，`返回match对象` |
| re.match()    | 从一个字符串的开始位置起匹配正则表达式，`返回match对象`      |
| re.findall()  | 搜索字符串，以列表类型返回全部能匹配的子串                   |
| re.split()    | 将一个字符串按照正则表达式匹配结果进行分隔，返回列表类型     |
| re.finditer() | 搜索字符串，返回一个匹配结果的迭代类型，`每个迭代对象是match对象` |
| re.sub()      | 在一个字符串中替换所有匹配正则表达式的子串，返回替换后的字符串 |

> 正则表达式可以包含一些可选标志修饰符来控制匹配的模式。修饰符被指定为一个可选的标志。 多个标志可以通过按位 OR(|) 它们来指定。如 re.I | re.M 被设置成 I 和 M 标志：
>
> | 修饰符 | 描述                                                         |
> | ------ | ------------------------------------------------------------ |
> | re.I   | 使匹配对大小写不敏感                                         |
> | re.L   | 做本地化识别（locale-aware）匹配                             |
> | re.M   | 多行匹配，影响 ^ 和 $                                        |
> | re.S   | 使 . 匹配包括换行在内的所有字符                              |
> | re.U   | 根据Unicode字符集解析字符。这个标志影响 \w, \W, \b, \B.      |
> | re.X   | 该标志通过给予你更灵活的格式以便你将正则表达式写得更易于理解。 |

##### 函数具体用法

###### compile(pattern)：创建模式对象

```python
import re
pat=re.compile("A")
#m=pat.search("CBA")
m=pat.search("ABC")
#等价于 re.search( A , CBA )
print(m)
#<re.Match object; span=(2, 3), match='A'> 表示匹配到了
m=pat.search("CBD")
print(m) #None 表示没匹配到
```

###### search(pattern,string)：在字符串中寻找模式

```python
import re
m = re.search("asd" , "ASDasd" )
print(m)
# <_sre.SRE_Match object at 0xb72cd6e8> #匹配到了，返回MatchObject（True）
m = re.search("asd" , "ASDASD" )
print(m)     #表示没匹配到返回None(False)
```

###### match(pattern,string)：在字符串开始处匹配模式

```python
# 等价于
pat=re.compile( "a" )
print(pat.match( "Aasd" ))
#输出None
print(pat.match("aASD" ))
#输出 <_sre.SRE_Match object at 0xb72cd6e8>
# 上面的函数返回都可以在if条件语句中进行判断：
if pat.search("asd"):
print ("OK") #OK #找到返回
if re.search("a","ASD" ):
print ("OK") #没有找到
```

###### split(pattern,string)：根据模式分割字符串,返回列表

```python
re.split( , , a,s,d,asd )
[ a , s , d , asd ] #返回列表
pat = re.compile( , )
pat.split( a,s,d,asd )
[ a , s , d , asd ] #返回列表
re.split( [, ]+ , a , s ,d ,,,,,asd ) #正则匹配：[, ]+
[ a , s , d , asd ]
re.split( [, ]+ , a , s ,d ,,,,,asd ,maxsplit=2) # maxsplit 最多分割次数
[ a , s , d ,,,,,asd ]
pat = re.compile( [, ]+ ) #正则匹配：[, ]+
pat.split( a , s ,d ,,,,,asd ,maxsplit=2) # maxsplit 最多分割次数
[ a , s , d ,,,,,asd ]
```

###### findall(pattern,string)：列表形式返回匹配项

```python
import re
print(re.findall( "a" , "ASDaDFGAa" ))
#[ a , a ] #列表形式返回匹配到的字符串
pat = re.compile( "a" )
print(pat.findall( "ASDaDFGAa" ))
#[ a , a ] #列表形式返回匹配到的字符串
pat = re.compile( "[A-Z]+" ) #正则匹配：[A-Z]+ 前一个字符`1`次或无限次扩展
print(pat.findall( "ASDcDFGAa" ))
#[ ASD , DFGA ] #找到匹配到的字符串
pat = re.compile( [A-Z] )
pat.findall( ASDcDFGAa )
[ A , S , D , D , F , G , A ] #找到匹配到的字符串
pat = re.compile( [A-Za-z] ) #正则匹配：[A-Za-z]+ 匹配所有字母
pat.findall( ASDcDFGAa )
[ A , S , D , c , D , F , G , A , a ]
```

###### sub(pat,repl,string) ：用repl替换 pat匹配项 (留的是中间的，因为中间在中心)

```python
re.sub( a , A , abcasd ) #找到a用A替换，后面见和group的配合使用
AbcAsd
pat = re.compile( a )
pat.sub( A , abcasd )
AbcAsd
pat=re.compile(r www.(.*)..{3} ) #正则表达式
#在Python的string前面加上‘r’， 是为了告诉编译器这个string是个raw string，不要转译反斜杠
#例如， 在raw string中，是两个字符，和n， 而不会转译为换行符。
#由于正则表达式和 会有冲突，因此，当一个字符串使用了正则表达式后，最好在前面加上 r 。
#与大多数编程语言相同，正则表达式里使用""作为转义字符，这就可能造成反斜杠困扰。
#假如你需要匹配文本中的字符""，那么使用编程语言表示的正则表达式里将需要4个反斜杠"\\"：
#前两个和后两个分别用于在编程语言里转义成反斜杠，转换成两个反斜杠后再在正则表达式里转义成一个反斜杠。
#Python里的原生字符串很好地解决了这个问题，这个例子中的正则表达式可以使用r"\"表示。
#同样，匹配一个数字的"\d"可以写成r"d"。
#有了原生字符串，你再也不用担心是不是漏写了反斜杠，写出来的表达式也更直观。
#不是说 加了r 就没有转译功能，好乱，就直接记住1句话：
#当一个字符串使用了正则表达式后，最好在前面加上 r ，这样你再也不用担心是不是漏写了反斜杠，写出来的表达式也更直观
pat.match( www.dxy.com ).group(1)
dxy
re.sub(r www.(.*)..{3} ,r , hello,www.dxy.com )
pat.sub(r , hello,www.dxy.com )
hello,dxy
# r 1 是第一组的意思
#通过正则匹配找到符合规则的"www.dxy.com" ，取得 组1字符串 去替换 整个匹配。
pat=re.compile(r (w+) (w+) ) #正则表达式
s= hello world ! hello hz !
pat.findall( hello world ! hello hz ! )
[( hello , world ), ( hello , hz )]
pat.sub(r ,s) #通过正则得到组1(hello)，组2(world)，再通过sub去替换。
即组1替换组2，组2替换组1，调换位置。
world hello!hz hello!
```

### xlwt模块

```python
import xlwt #导入模块
workbook = xlwt.Workbook(encoding='utf-8') #创建workbook 对象
worksheet = workbook.add_sheet('sheet1') #创建工作表sheet
worksheet.write(0, 0, 'hello') #往表中写内容,第一各参数 行,第二个参数列,第三个参数内容
workbook.save('students.xls') #保存表为students.xls
```

将九九乘法表显示在表格中，每个单元格1个公式

```python
workbook = xlwt.Workbook(encoding='utf-8') #创建workbook 对象
worksheet = workbook.add_sheet('sheet1') #创建工作表sheet
for i in range(0,9):
for j in range(0,i+1):
worksheet.write(i, j, "%d * %d = %d"%(i+1,j+1,(i+1)*(j+1)))
# worksheet.write(0, 0, 'hello') #往表中写内容,第一各参数 行,第二个参数列,第三个参数内容
workbook.save('students.xls') #保存表为students.xls
```

